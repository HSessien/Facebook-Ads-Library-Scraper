"""
display_utils.py
Fonctions utilitaires pour l'affichage des tableaux de publicit√©s
"""

import streamlit as st
import pandas as pd
import json
import os
import sys
import time
import subprocess
from datetime import datetime


# ============================================
# CONFIGURATION DES COLONNES POUR TABLEAUX
# ============================================

def get_column_config():
    """
    Retourne la configuration standard des colonnes pour st.data_editor
    """
    return {
        "üö´ Blacklist": st.column_config.CheckboxColumn(
            "üö´",
            help="Ajouter √† la blacklist",
            default=False,
            width="small"
        ),
        "‚≠ê Whitelist": st.column_config.CheckboxColumn(
            "‚≠ê",
            help="Ajouter √† la whitelist",
            default=False,
            width="small"
        ),
        "scraped_at": st.column_config.TextColumn(
            "Date scraping",
            help="Date et heure du scraping",
            width="medium"
        ),
        "media_url": st.column_config.LinkColumn(
            "M√©dia",
            help="Image ou vid√©o de la publicit√©",
            display_text="üì• Voir",
            width="small"
        ),
        "cta_url": st.column_config.LinkColumn(
            "Lien CTA",
            help="Destination du bouton d'action",
            display_text="üîó Ouvrir",
            width="small"
        ),
        "ad_library_url": st.column_config.LinkColumn(
            "Voir pub",
            help="Ouvrir dans Facebook Ads Library",
            display_text="üîó Ouvrir",
            width="small"
        ),
        "page_id": st.column_config.TextColumn(
            "Page ID",
            help="Identifiant de la page Facebook",
            width="small"
        ),
        "advertiser": st.column_config.TextColumn(
            "Annonceur",
            help="Nom de la page Facebook",
            width="medium"
        ),
        "country": st.column_config.TextColumn(
            "Pays",
            help="Pays de diffusion",
            width="small"
        ),
        "ad_status": st.column_config.TextColumn(
            "Statut",
            help="Active ou Inactive",
            width="small"
        ),
        "media_type": st.column_config.TextColumn(
            "Type m√©dia",
            help="Image, vid√©o ou N/A",
            width="small"
        ),
        "text": st.column_config.TextColumn(
            "Texte",
            help="Contenu textuel de la publicit√©",
            width="large"
        ),
        "start_date": st.column_config.TextColumn(
            "Date d√©but",
            help="Date de lancement de la pub",
            width="medium"
        ),
    }


def get_disabled_columns(include_scraped_at=False):
    """
    Retourne la liste des colonnes en lecture seule
    
    Args:
        include_scraped_at: Inclure scraped_at dans les colonnes d√©sactiv√©es
    """
    disabled = [
        "media_url", "cta_url", "ad_library_url", "page_id",
        "advertiser", "country", "ad_status", "media_type",
        "text", "start_date"
    ]
    
    if include_scraped_at:
        disabled.append("scraped_at")
    
    return disabled


def prepare_dataframe_for_display(results, include_scraped_at=False):
    """
    Pr√©pare un DataFrame avec les colonnes dans le bon ordre
    
    Args:
        results: Liste de dictionnaires (publicit√©s)
        include_scraped_at: Inclure la colonne scraped_at
    
    Returns:
        DataFrame pandas pr√™t pour l'affichage
    """
    if not results:
        return pd.DataFrame()
    
    df = pd.DataFrame(results)
    
    # Ordre des colonnes
    if include_scraped_at:
        colonnes_a_afficher = [
            'scraped_at',
            'media_url', 'cta_url', 'ad_library_url', 'page_id',
            'advertiser', 'country', 'ad_status', 'media_type',
            'text', 'start_date',
        ]
    else:
        colonnes_a_afficher = [
            'media_url', 'cta_url', 'ad_library_url', 'page_id',
            'advertiser', 'country', 'ad_status', 'media_type',
            'text', 'start_date',
        ]
    
    # Filtrer uniquement les colonnes existantes
    colonnes_existantes = [col for col in colonnes_a_afficher if col in df.columns]
    df = df[colonnes_existantes]
    
    # Ajouter les colonnes de s√©lection
    df.insert(0, '‚≠ê Whitelist', False)
    df.insert(0, 'üö´ Blacklist', False)
    
    return df


# ============================================
# AFFICHAGE DU TABLEAU AVEC GESTION COMPL√àTE
# ============================================

def display_ads_table(results, entry_id, search_key="", include_scraped_at=False, session_state=None, config=None):
    """
    Affiche le tableau de publicit√©s avec toutes les fonctionnalit√©s
    (s√©lection blacklist/whitelist, t√©l√©chargements, validation)
    
    Args:
        results: Liste des publicit√©s √† afficher
        entry_id: ID unique pour les cl√©s des widgets
        search_key: Suffixe pour diff√©rencier les tables (ex: recherche active)
        include_scraped_at: Afficher la colonne scraped_at
        session_state: st.session_state pour acc√©der √† la config
        config: Configuration (headless, etc.)
    """
    
    if not results:
        st.warning("Aucun r√©sultat √† afficher")
        return
    
    st.info(f"üìä {len(results)} r√©sultat(s) affich√©(s)")
    
    # Pr√©parer le DataFrame
    df = prepare_dataframe_for_display(results, include_scraped_at)
    
    # Afficher le tableau √©ditable
    edited_df = st.data_editor(
        df,
        width="stretch",
        hide_index=False,
        key=f"ads_editor_{entry_id}_{search_key}",
        column_config=get_column_config(),
        disabled=get_disabled_columns(include_scraped_at)
    )
    
    # ============================================
    # VALIDATION ET BOUTONS D'AJOUT AUX LISTES
    # ============================================
    
    both_checked = edited_df[(edited_df['üö´ Blacklist'] == True) & (edited_df['‚≠ê Whitelist'] == True)]
    
    if not both_checked.empty:
        st.error("‚ùå Une page ne peut pas √™tre √† la fois en blacklist ET whitelist. Veuillez d√©cocher l'une des deux options.")
    else:
        col_btn1, col_btn2 = st.columns(2)
        
        # ============================================
        # BOUTON BLACKLIST
        # ============================================
        with col_btn1:
            blacklist_pages = edited_df[edited_df['üö´ Blacklist'] == True]
            if not blacklist_pages.empty:
                if st.button(
                    f"‚úÖ Ajouter {len(blacklist_pages)} page(s) √† la blacklist",
                    type="primary",
                    key=f"add_blacklist_{entry_id}_{search_key}"
                ):
                    _add_to_list(blacklist_pages, 'blacklist', entry_id, config)
        
        # ============================================
        # BOUTON WHITELIST
        # ============================================
        with col_btn2:
            whitelist_pages = edited_df[edited_df['‚≠ê Whitelist'] == True]
            if not whitelist_pages.empty:
                if st.button(
                    f"‚úÖ Ajouter {len(whitelist_pages)} page(s) √† la whitelist",
                    type="primary",
                    key=f"add_whitelist_{entry_id}_{search_key}"
                ):
                    _add_to_list(whitelist_pages, 'whitelist', entry_id, config)
    
    # ============================================
    # BOUTONS DE T√âL√âCHARGEMENT
    # ============================================
    st.markdown("---")
    col_dl1, col_dl2 = st.columns(2)
    
    with col_dl1:
        df_export = pd.DataFrame(results)
        csv = df_export.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "üì• T√©l√©charger CSV",
            data=csv,
            file_name=f"facebook_ads_{entry_id}.csv",
            mime="text/csv",
            key=f"csv_{entry_id}_{search_key}"
        )
    
    with col_dl2:
        json_str = json.dumps(results, ensure_ascii=False, indent=2)
        st.download_button(
            "üì• T√©l√©charger JSON",
            data=json_str,
            file_name=f"facebook_ads_{entry_id}.json",
            mime="application/json",
            key=f"json_{entry_id}_{search_key}"
        )


# ============================================
# FONCTION PRIV√âE : AJOUT AUX LISTES
# ============================================

def _add_to_list(pages_df, list_type, entry_id, config):
    """
    Ajoute des pages √† la blacklist ou whitelist via le script externe
    
    Args:
        pages_df: DataFrame des pages s√©lectionn√©es
        list_type: 'blacklist' ou 'whitelist'
        entry_id: ID pour le fichier temporaire
        config: Configuration (headless, etc.)
    """
    
    # Pr√©parer la liste des IDs
    page_ids = pages_df['page_id'].tolist()
    
    # Sauvegarder dans un fichier temporaire
    temp_file = f"temp_batch_{entry_id}_{list_type}.json"
    with open(temp_file, 'w', encoding='utf-8') as f:
        json.dump(page_ids, f)
    
    # Conteneurs pour le statut
    status_container = st.empty()
    progress_container = st.empty()
    
    with st.spinner(f"üîç Traitement de {len(page_ids)} page(s)..."):
        # Lancer le script en mode batch
        cmd = [
            sys.executable,
            'fb_id_retriever.py',
            list_type,
            '--batch',
            temp_file
        ]
        
        if config and config.get('headless', True):
            cmd.append('--headless')
        
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # Afficher la progression
        max_wait = 300  # 5 minutes max
        elapsed = 0
        
        while elapsed < max_wait:
            status = _get_fb_id_status()
            
            if status:
                total = status.get('total', len(page_ids))
                current = status.get('current', 0)
                
                if total > 0:
                    progress_container.progress(int((current / total) * 100))
                
                status_container.info(
                    f"üìä {status.get('message', 'Traitement en cours...')}\n"
                    f"Page actuelle: {status.get('current_page', 'N/A')}"
                )
                
                if status.get('status') in ['completed', 'error']:
                    break
            
            if os.path.exists('fb_id_result.json'):
                break
            
            time.sleep(1)
            elapsed += 1
        
        # R√©cup√©rer le r√©sultat
        if os.path.exists('fb_id_result.json'):
            with open('fb_id_result.json', 'r', encoding='utf-8') as f:
                result = json.load(f)
            
            success_count = result.get('success_count', 0)
            
            if success_count > 0:
                st.success(f"‚úÖ {success_count}/{len(page_ids)} page(s) ajout√©e(s) √† la {list_type} !")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è Aucune page n'a pu √™tre ajout√©e")
        else:
            st.error("‚ùå Erreur lors du traitement")
        
        # Nettoyer le fichier temporaire
        if os.path.exists(temp_file):
            os.remove(temp_file)


def _get_fb_id_status():
    """R√©cup√®re le statut du script fb_id_retriever"""
    if os.path.exists('fb_id_status.json'):
        try:
            with open('fb_id_status.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return None
    return None


# ============================================
# FONCTION DE FUSION DES PUBLICIT√âS
# ============================================

def fusionner_publicites(all_ads):
    """
    Fusionne les publicit√©s en doublon (m√™me ad_id) en compl√©tant les donn√©es manquantes
    
    Args:
        all_ads: Liste de toutes les publicit√©s (avec potentiels doublons)
    
    Returns:
        Liste de publicit√©s uniques avec donn√©es fusionn√©es
    """
    pubs_par_id = {}
    
    for ad in all_ads:
        ad_id = ad.get('ad_id')
        
        if not ad_id or ad_id == 'N/A':
            continue
        
        if ad_id not in pubs_par_id:
            # Premi√®re occurrence
            pubs_par_id[ad_id] = ad.copy()
        else:
            # Doublon : fusionner
            existing = pubs_par_id[ad_id]
            
            # Compl√©ter les champs 'N/A' avec les nouvelles valeurs
            for key, value in ad.items():
                if existing.get(key) in ['N/A', '', None] and value not in ['N/A', '', None]:
                    existing[key] = value
            
            # Garder la date de scraping la plus r√©cente
            if ad.get('scraped_at', '') > existing.get('scraped_at', ''):
                existing['scraped_at'] = ad['scraped_at']
    
    return list(pubs_par_id.values())